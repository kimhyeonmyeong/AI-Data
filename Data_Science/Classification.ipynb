{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "- Binary Classification(SVM, Logistic Regression)\n",
    "- Multi Classification(SVM, Logistic Regression)\n",
    "- K-Fold cross validation\n",
    "- 정확도(accuracy, precision, recall, f1_score) 추출 및 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "\n",
    "def load_score_data():\n",
    "    xlsx_file = 'db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xlsx_file)\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', user='root', password='gusaud123', db='university')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    drop_sql = \"\"\"drop table if exists db_score\"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    import sqlalchemy\n",
    "    \n",
    "    database_username = 'root'\n",
    "    database_password = 'gusaud123'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'university'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.\n",
    "                                                    format(database_username, database_password,\n",
    "                                                          database_ip, database_name))\n",
    "    db_score.to_sql(con=database_connection, name='db_score', if_exists='replace')\n",
    "\n",
    "# mysql 테이블 구축\n",
    "#load_score_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for SVM with test_split\n",
      "accuracy=0.709677\n",
      "precision=0.500000\n",
      "recall=0.555556\n",
      "f1_score=0.526316\n",
      "\n",
      "\n",
      "Evaluation for LogisticRegression with test_split\n",
      "accuracy=0.718750\n",
      "precision=1.000000\n",
      "recall=0.100000\n",
      "f1_score=0.181818\n",
      "\n",
      "\n",
      "Evaluation for SVM with k_fold\n",
      "average_accuracy = 0.683625730994152\n",
      "average_precision = 0.6088888888888888\n",
      "average_recall = 0.46095238095238095\n",
      "average_f1_score = 0.44948384948384945\n",
      "\n",
      "\n",
      "Evaluation for LogisticRegression with k_fold\n",
      "average_accuracy = 0.6594736842105263\n",
      "average_precision = 0.8666666666666667\n",
      "average_recall = 0.15508658008658008\n",
      "average_f1_score = 0.26015873015873014\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classification_performance_eval(y, y_predict):\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for y, yp in zip(y, y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1 \n",
    "        elif y == -1 and yp == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "\n",
    "    if (tp == 0):\n",
    "        tp = 1\n",
    "        \n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "def Svm_Performance_train_test_split(X,y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state=42)\n",
    "    \n",
    "    svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_predict = svm_model.predict(X_test) # 테스트\n",
    "    \n",
    "    accuracy, precision, recall, f1_score = classification_performance_eval(y_test, y_predict)\n",
    "    \n",
    "    print(\"Evaluation for SVM with test_split\")    \n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    print(\"precision=%f\" %precision)\n",
    "    print(\"recall=%f\" %recall)\n",
    "    print(\"f1_score=%f\" %f1_score)\n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "def LogisticRegression_Performance_train_test_split(X,y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, shuffle = True, random_state=42)\n",
    "\n",
    "    \n",
    "    # logistic 모델 적용\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = log_reg.predict(X_test)\n",
    "\n",
    "    accuracy, precision, recall, f1_score = classification_performance_eval(y_test, y_predict)\n",
    "    \n",
    "    print(\"Evaluation for LogisticRegression with test_split\")    \n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    print(\"precision=%f\" %precision)\n",
    "    print(\"recall=%f\" %recall)\n",
    "    print(\"f1_score=%f\" %f1_score)\n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "def SVM_performance_k_fold_cross_validation(X, y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold (n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X): \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "        svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        y_predict = svm_model.predict(X_test) # 테스트\n",
    "       \n",
    "    \n",
    "        acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)    \n",
    "        accuracy.append(acc)\n",
    "        precision.append(prec)\n",
    "        recall.append(rec)\n",
    "        f1_score.append(f1)\n",
    "    \n",
    "    import statistics\n",
    "    print(\"Evaluation for SVM with k_fold\")\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    print(\"average_precision =\", statistics.mean(precision))\n",
    "    print(\"average_recall =\", statistics.mean(recall))\n",
    "    print(\"average_f1_score =\", statistics.mean(f1_score))\n",
    "    print('\\n')\n",
    "\n",
    "def LogisticRegression_performance_k_fold_cross_validation(X, y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold (n_splits=5, random_state=42, shuffle=True)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X): \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # logistic 모델 적용\n",
    "        log_reg = LogisticRegression()\n",
    "        log_reg.fit(X_train, y_train)\n",
    "\n",
    "        y_predict = log_reg.predict(X_test)\n",
    "        acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)    \n",
    "        accuracy.append(acc)\n",
    "        precision.append(prec)\n",
    "        recall.append(rec)\n",
    "        f1_score.append(f1)\n",
    "    \n",
    "    import statistics\n",
    "    \n",
    "    print(\"Evaluation for LogisticRegression with k_fold\")\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    print(\"average_precision =\", statistics.mean(precision))\n",
    "    print(\"average_recall =\", statistics.mean(recall))\n",
    "    print(\"average_f1_score =\", statistics.mean(f1_score))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "# MySql에서 db_score데이터 불러오기\n",
    "conn = pymysql.connect(host='localhost', user='root', password='gusaud123', db='university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "data = curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "X = [ (t['homework'], t['discussion'], t['final'] )  for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "\n",
    "y = [ 1 if (t['grade'] == 'B') else -1 for t in data ]\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "Svm_Performance_train_test_split(X,y)\n",
    "LogisticRegression_Performance_train_test_split(X,y)\n",
    "SVM_performance_k_fold_cross_validation(X, y)\n",
    "LogisticRegression_performance_k_fold_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for SVM with test_split\n",
      "accuracy=0.612903\n",
      "precision(A)=0.687500\n",
      "recall(A)=1.000000\n",
      "f1_score(A)=0.814815\n",
      "\n",
      "\n",
      "precision(B)=0.454545\n",
      "recall(B)=0.555556\n",
      "f1_score(B)=0.500000\n",
      "\n",
      "\n",
      "precision(C)=0.750000\n",
      "recall(C)=0.272727\n",
      "f1_score(C)=0.400000\n",
      "\n",
      "\n",
      "Evaluation for LogisticRegression with test_split\n",
      "accuracy=0.709677\n",
      "precision(A)=0.733333\n",
      "recall(A)=1.000000\n",
      "f1_score(A)=0.846154\n",
      "\n",
      "\n",
      "precision(B)=0.545455\n",
      "recall(B)=0.666667\n",
      "f1_score(B)=0.600000\n",
      "\n",
      "\n",
      "precision(C)=1.000000\n",
      "recall(C)=0.454545\n",
      "f1_score(C)=0.625000\n",
      "\n",
      "\n",
      "Evaluation for SVM with k_fold\n",
      "average_accuracy = 0.6374269005847953\n",
      "average_precision(A) = 0.7361111111111112\n",
      "average_recall(A) = 0.8292857142857143\n",
      "average_f1_score(A) = 0.7080175706646294\n",
      "\n",
      "\n",
      "average_precision(B) = 0.4676190476190476\n",
      "average_recall(B) = 0.560952380952381\n",
      "average_f1_score(B) = 0.5017366946778712\n",
      "\n",
      "\n",
      "average_precision(C) = 0.7542857142857143\n",
      "average_recall(C) = 0.685\n",
      "average_f1_score(C) = 0.6446153846153846\n",
      "\n",
      "\n",
      "Evaluation for LogisticRegression with k_fold\n",
      "average_accuracy = 0.6584795321637427\n",
      "average_precision(A) = 0.6961111111111111\n",
      "average_recall(A) = 0.8542857142857143\n",
      "average_f1_score(A) = 0.7016450216450216\n",
      "\n",
      "\n",
      "average_precision(B) = 0.5092857142857142\n",
      "average_recall(B) = 0.5190476190476191\n",
      "average_f1_score(B) = 0.4938528138528139\n",
      "\n",
      "\n",
      "average_precision(C) = 0.7971861471861472\n",
      "average_recall(C) = 0.7271428571428571\n",
      "average_f1_score(C) = 0.7149715781294728\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Multiclassification_performanceA_eval(y, y_predict):c\n",
    "    a= y\n",
    "    b= y\n",
    "    c=y\n",
    "    A = y_predict\n",
    "    B = y_predict\n",
    "    C = y_predict\n",
    "    \n",
    "    tpA, tnA, fpA, fnA = 0,0,0,0\n",
    "    \n",
    "    tpB, tnB, fpB, fnB = 0,0,0,0\n",
    "    \n",
    "    tpC, tnC, fpC, fnC = 0,0,0,0\n",
    "    \n",
    "    for y, yp in zip(a, A):\n",
    "        \n",
    "        if y == 1 and yp == 1:\n",
    "            tpA += 1\n",
    "        elif y == 1 and (yp == 2 or yp == 3):\n",
    "            fnA += 1 \n",
    "        elif (y == 2 or y == 3)and yp == 1 :\n",
    "            fpA += 1\n",
    "        elif (y == 2 or y == 3) and (yp == 2 or yp ==3):\n",
    "            tnA += 1\n",
    "    \n",
    "    \n",
    "    for y, yp in zip(b, B):\n",
    "        \n",
    "        if (y == 2 and yp == 2):\n",
    "            tpB += 1\n",
    "        elif y == 2 and (yp == 1 or yp == 3):\n",
    "            fnB += 1 \n",
    "        elif (y == 1 or y == 3)and yp == 2 :\n",
    "            fpB += 1\n",
    "        elif (y == 1 or y == 3) and (yp == 1 or yp ==3):\n",
    "            tnB += 1\n",
    "\n",
    "    for y, yp in zip(c, C):\n",
    "        if (y == 3 and yp == 3):\n",
    "            tpC += 1\n",
    "        elif y == 3  and (yp == 1 or yp == 2):\n",
    "            fnC += 1 \n",
    "        elif (y == 1 or y == 2)and yp == 3 :\n",
    "            fpC += 1\n",
    "        elif (y == 1 or y == 2) and (yp == 1 or yp ==2):\n",
    "            tnC += 1                \n",
    "            \n",
    "    if (tpA == 0):\n",
    "        tpA = 1\n",
    "    if (tpB == 0):\n",
    "        tpB = 1\n",
    "    if (tpC == 0):\n",
    "        tpC = 1\n",
    "        \n",
    "    accuracy = (tpA + tpB  +tpC )/(tpA+tnA+fpA+fnA)\n",
    "    \n",
    "    precisionA = tpA/(tpA+fpA)\n",
    "    recallA = tpA/(tpA+fnA)\n",
    "    f1_scoreA = 2*precisionA*recallA/(precisionA+recallA)\n",
    "    \n",
    "    precisionB = tpB/(tpB+fpB)\n",
    "    recallB = tpB/(tpB+fnB)\n",
    "    f1_scoreB = 2*precisionB*recallB/(precisionB+recallB)\n",
    "    \n",
    "    precisionC = tpC/(tpC+fpC)\n",
    "    recallC = tpC/(tpC+fnC)\n",
    "    f1_scoreC = 2*precisionC*recallC/(precisionC+recallC)\n",
    "    \n",
    "    return accuracy, precisionA, recallA, f1_scoreA, precisionB, recallB, f1_scoreB, precisionC, recallC, f1_scoreC\n",
    "\n",
    "\n",
    "def Svm_Performance_train_test_split(X,y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state=42)\n",
    "\n",
    "    #데이터 스케일링\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
    "    svm_model.fit(X_train_std, y_train) # SVM 분류 모델 훈련\n",
    "    \n",
    "    y_predict = svm_model.predict(X_test_std) # 테스트\n",
    "    \n",
    "    \n",
    "    accuracy, precisionA, recallA, f1_scoreA, precisionB, recallB, f1_scoreB, precisionC, recallC, f1_scoreC = Multiclassification_performanceA_eval(y_test, y_predict)\n",
    "    \n",
    "    \n",
    "    print(\"Evaluation for SVM with test_split\")\n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    print(\"precision(A)=%f\" %precisionA)\n",
    "    print(\"recall(A)=%f\" %recallA)\n",
    "    print(\"f1_score(A)=%f\" %f1_scoreA)\n",
    "    print('\\n')\n",
    "    print(\"precision(B)=%f\" %precisionB)\n",
    "    print(\"recall(B)=%f\" %recallB)\n",
    "    print(\"f1_score(B)=%f\" %f1_scoreB)\n",
    "    print('\\n')\n",
    "    print(\"precision(C)=%f\" %precisionC)\n",
    "    print(\"recall(C)=%f\" %recallC)\n",
    "    print(\"f1_score(C)=%f\" %f1_scoreC)\n",
    "    print('\\n')\n",
    "\n",
    "def LogisticRegression_Performance_train_test_split(X,y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, shuffle = True, random_state=42)\n",
    "\n",
    "    \n",
    "    #데이터 스케일링\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_std, y_train)\n",
    "    \n",
    "    y_predict = log_reg.predict(X_test_std)\n",
    "\n",
    "    accuracy, precisionA, recallA, f1_scoreA, precisionB, recallB, f1_scoreB, precisionC, recallC, f1_scoreC = Multiclassification_performanceA_eval(y_test, y_predict)\n",
    "    \n",
    "    \n",
    "    print(\"Evaluation for LogisticRegression with test_split\")\n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    print(\"precision(A)=%f\" %precisionA)\n",
    "    print(\"recall(A)=%f\" %recallA)\n",
    "    print(\"f1_score(A)=%f\" %f1_scoreA)\n",
    "    print('\\n')\n",
    "    print(\"precision(B)=%f\" %precisionB)\n",
    "    print(\"recall(B)=%f\" %recallB)\n",
    "    print(\"f1_score(B)=%f\" %f1_scoreB)\n",
    "    print('\\n')\n",
    "    print(\"precision(C)=%f\" %precisionC)\n",
    "    print(\"recall(C)=%f\" %recallC)\n",
    "    print(\"f1_score(C)=%f\" %f1_scoreC)\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def SVM_performance_k_fold_cross_validation(X, y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold (n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    accuracy = []\n",
    "    precisionA = []\n",
    "    recallA = []\n",
    "    f1_scoreA = []\n",
    "    \n",
    "    precisionB = []\n",
    "    recallB = []\n",
    "    f1_scoreB = []\n",
    "    \n",
    "    precisionC = []\n",
    "    recallC = []\n",
    "    f1_scoreC = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X): \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #데이터 스케일링\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "    \n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "        \n",
    "        #svm모델 적용\n",
    "        svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
    "        svm_model.fit(X_train_std, y_train) # SVM 분류 모델 훈련\n",
    "\n",
    "        y_predict = svm_model.predict(X_test_std) # 테스트        \n",
    "    \n",
    "        acc, precA, recA, f1A, precB, recB, f1B, precC, recC, f1C = Multiclassification_performanceA_eval(y_test, y_predict)\n",
    "        \n",
    "        accuracy.append(acc)\n",
    "        precisionA.append(precA)\n",
    "        recallA.append(recA)\n",
    "        f1_scoreA.append(f1A)\n",
    "        \n",
    "        precisionB.append(precB)\n",
    "        recallB.append(recB)\n",
    "        f1_scoreB.append(f1B)\n",
    "        \n",
    "        precisionC.append(precC)\n",
    "        recallC.append(recC)\n",
    "        f1_scoreC.append(f1C)       \n",
    "    \n",
    "    import statistics\n",
    "    print(\"Evaluation for SVM with k_fold\")\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    print(\"average_precision(A) =\", statistics.mean(precisionA))\n",
    "    print(\"average_recall(A) =\", statistics.mean(recallA))\n",
    "    print(\"average_f1_score(A) =\", statistics.mean(f1_scoreA))\n",
    "    print('\\n')    \n",
    "    print(\"average_precision(B) =\", statistics.mean(precisionB))\n",
    "    print(\"average_recall(B) =\", statistics.mean(recallB))\n",
    "    print(\"average_f1_score(B) =\", statistics.mean(f1_scoreB))\n",
    "    print('\\n')\n",
    "    print(\"average_precision(C) =\", statistics.mean(precisionC))\n",
    "    print(\"average_recall(C) =\", statistics.mean(recallC))\n",
    "    print(\"average_f1_score(C) =\", statistics.mean(f1_scoreC))    \n",
    "    print('\\n')\n",
    "\n",
    "def LogisticRegression_performance_k_fold_cross_validation(X, y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold (n_splits=5, random_state=42, shuffle=True)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    accuracy = []\n",
    "    precisionA = []\n",
    "    recallA = []\n",
    "    f1_scoreA = []\n",
    "    \n",
    "    precisionB = []\n",
    "    recallB = []\n",
    "    f1_scoreB = []\n",
    "    \n",
    "    precisionC = []\n",
    "    recallC = []\n",
    "    f1_scoreC = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X): \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # 데이터 스케일링\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "\n",
    "        X_train_std = sc.transform(X_train)\n",
    "        X_test_std = sc.transform(X_test)\n",
    "\n",
    "        # logistic 모델 적용\n",
    "        log_reg = LogisticRegression()\n",
    "        log_reg.fit(X_train_std, y_train)\n",
    "\n",
    "        y_predict = log_reg.predict(X_test_std)\n",
    "        acc, precA, recA, f1A, precB, recB, f1B, precC, recC, f1C = Multiclassification_performanceA_eval(y_test, y_predict)\n",
    "        \n",
    "        accuracy.append(acc)\n",
    "        precisionA.append(precA)\n",
    "        recallA.append(recA)\n",
    "        f1_scoreA.append(f1A)\n",
    "        \n",
    "        precisionB.append(precB)\n",
    "        recallB.append(recB)\n",
    "        f1_scoreB.append(f1B)\n",
    "        \n",
    "        precisionC.append(precC)\n",
    "        recallC.append(recC)\n",
    "        f1_scoreC.append(f1C)     \n",
    "    \n",
    "    import statistics\n",
    "    \n",
    "    print(\"Evaluation for LogisticRegression with k_fold\")\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    print(\"average_precision(A) =\", statistics.mean(precisionA))\n",
    "    print(\"average_recall(A) =\", statistics.mean(recallA))\n",
    "    print(\"average_f1_score(A) =\", statistics.mean(f1_scoreA))\n",
    "    print('\\n')    \n",
    "    print(\"average_precision(B) =\", statistics.mean(precisionB))\n",
    "    print(\"average_recall(B) =\", statistics.mean(recallB))\n",
    "    print(\"average_f1_score(B) =\", statistics.mean(f1_scoreB))\n",
    "    print('\\n')\n",
    "    print(\"average_precision(C) =\", statistics.mean(precisionC))\n",
    "    print(\"average_recall(C) =\", statistics.mean(recallC))\n",
    "    print(\"average_f1_score(C) =\", statistics.mean(f1_scoreC))    \n",
    "    print('\\n')\n",
    "\n",
    "# MySql에서 db_score데이터 불러오기\n",
    "conn = pymysql.connect(host='localhost', user='root', password='gusaud123', db='university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "data = curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "X = [ (t['homework'], t['discussion'], t['final'] )  for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "y = [ (t['grade']) for t in data ]\n",
    "y = np.array(y)\n",
    "\n",
    "for i in range (0,len(y)):\n",
    "    if(y[i] == 'A'):\n",
    "        y[i] = 1\n",
    "    elif(y[i] == 'B'):\n",
    "        y[i] = 2 \n",
    "    else:\n",
    "        y[i] = 3\n",
    "     \n",
    "y = np.array(y, dtype = np.int64)\n",
    "\n",
    "Svm_Performance_train_test_split(X,y)\n",
    "LogisticRegression_Performance_train_test_split(X,y)\n",
    "SVM_performance_k_fold_cross_validation(X, y)\n",
    "LogisticRegression_performance_k_fold_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
