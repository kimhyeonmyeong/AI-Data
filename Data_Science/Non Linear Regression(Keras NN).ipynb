{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Linear Regression(Keras NN)\n",
    "\n",
    "- Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer1 (Dense)        (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[0.37454012 0.95071431 0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452 0.05808361 0.86617615]\n",
      " [0.60111501 0.70807258 0.02058449 0.96990985]\n",
      " ...\n",
      " [0.4368507  0.72950823 0.7655129  0.15890817]\n",
      " [0.61022515 0.13535408 0.75137509 0.65695516]\n",
      " [0.95661462 0.06895802 0.05705472 0.28218707]]\n",
      "(500, 4)\n",
      "[ 3  5 10 20]\n",
      "(4,)\n",
      "[26.17030099 20.15238756 25.94774991 10.04536334 14.68054188 13.78171134\n",
      " 18.57551635 12.49542676 31.76384976 18.04758202 22.37229251 18.60742255\n",
      " 28.76290586 32.70911807  9.20427132 18.94521865 22.00946581 17.85484794\n",
      " 26.74259029  9.58607277 11.28594817 23.60607479 21.48355106 23.67432486\n",
      "  7.11792339 17.59131325 24.18401257  8.19323432 31.59294422 24.05630135\n",
      " 13.28385021 29.21410376 12.19085915 18.94082764 29.14340434 16.13630462\n",
      " 18.18818002 16.42156525 18.57955839 23.76520713 22.31566934 12.38555265\n",
      " 11.18419034 13.60781454 17.12420872 29.38428991 24.34998335 22.67355603\n",
      " 17.24125086 32.1317935  22.93416567 17.15002325 21.14446686 15.94400429\n",
      " 29.18945332 14.10544543 20.60761536 24.83268769 21.59477231 11.96083347\n",
      " 25.14283655 29.30290053 18.8023507  17.96897276 14.93275488 19.56272413\n",
      " 28.35580139 27.84231212 23.3111696  29.58022735 10.99546013 18.42342467\n",
      "  5.86575633 16.98422522 12.32493985 21.96676757 19.67966734 10.69856167\n",
      " 28.16857963  9.66255882 18.42131131 25.33203588 22.21410413  2.89814614\n",
      " 13.78309255 15.25125816 12.5317814  27.41429683 17.34482607 24.92019781\n",
      " 20.87581556 33.47382609  3.30639644 11.78976184 17.43276593 28.67704905\n",
      " 13.59175438 25.44342291 28.02130098 28.31977655 27.40380919 10.54653476\n",
      " 26.36695503 22.00629344 25.29563019 18.12329497 26.08970936 19.29820957\n",
      " 18.22071826 14.0169872  17.34326193 33.10221593 21.48583649 17.76891486\n",
      "  6.31675523 23.72645435 25.98997397 26.00602149 30.72150232 24.14564336\n",
      " 23.46351161 13.33246058 25.26177286 14.47677796 32.60780449 25.14614353\n",
      " 29.42729492 21.97700997  9.10803109 19.06325587 31.22836887 15.47478838\n",
      " 33.61610193 33.35225779 11.87431234 22.613468   19.21223815 28.66778008\n",
      " 22.29660372 21.50352265  5.83166818 17.67329    26.26670857 32.91411141\n",
      " 16.16020927 18.77878329  7.43715838 16.34941761 21.72109357  6.60453508\n",
      "  6.4439124  13.01453586 22.34355533 30.44573058 25.59482873 15.99549041\n",
      " 24.27409844 27.40986694 15.2155672  14.04831989 11.33503653 25.32989372\n",
      " 17.47105843 13.35592224 21.54147771 17.80315045  7.74284786 22.65422136\n",
      " 27.61479879 30.33024155 19.82247062 17.8876512  15.98921868 17.09564889\n",
      " 15.93851196  8.9112223  25.56095344 24.68648899 26.55319869 24.17731452\n",
      " 20.20856236 24.23563323 20.35731406 26.74323444 18.19057019 21.42543033\n",
      " 20.90448039 26.80622919 21.83087674 30.23839378 20.37745223 29.10994532\n",
      " 24.16789497 14.34020464 25.32233505 15.22737801 19.93799224 20.38054478\n",
      " 23.19851723 32.03851663 21.78159565 33.8096536  29.54508206 25.05392222\n",
      " 12.02040105 14.73008605 17.61398887 16.768432   15.66669271 24.00767646\n",
      " 25.35873625 24.31009052 21.1534843  11.98513904 10.43256785 19.65218466\n",
      " 10.19145591 17.4639208   8.35258499 11.15293956  7.33196512 15.58358827\n",
      " 26.85078381 16.25711452  8.20131214 15.23150536 21.73841486 14.94095458\n",
      " 19.16250738 17.06398527 30.98518731 15.90744494 22.28203856 13.74459684\n",
      " 18.3345064  27.70209563 21.0434721  25.91463784 17.94864938 19.21508897\n",
      " 14.50355993 16.77733816 30.45277237  9.82953042 19.94288231  8.42603086\n",
      " 21.24259359 27.72280589 10.20896918 22.85852288 27.63885961 30.62027895\n",
      " 26.16158342 29.59003015 14.21525474 33.2441327  31.71528503 18.39735271\n",
      " 16.98816847 12.60282891 22.27744226  9.55485956 23.04240308 24.80469669\n",
      " 22.6600849  24.57951847 10.54923624 11.13529766 19.64833581 26.73297891\n",
      " 25.56426396 15.64599644 27.55211511 11.2239117  17.39199986 33.41194569\n",
      " 23.98138942 16.50468407 21.88744846 10.90806368 33.2560994  14.75894466\n",
      " 20.56855031 10.69925948 22.68337484 23.30788974 27.33753165 31.71211253\n",
      " 27.73356482 15.18355005 22.34315326 24.04281126 28.24734103 21.33422311\n",
      " 22.31004998 30.56511788 14.22927003 17.76066636 23.03038322 18.8630993\n",
      " 10.09116407 22.06897455 20.09605601 16.81713372 16.65994233 27.80354656\n",
      " 14.91205972 19.53868713 15.68217965 19.35156888 32.09373678  8.37714595\n",
      " 24.44161506 17.4396243  16.34106432 18.00279829 14.92080832 28.41064134\n",
      " 10.44132013 18.06216651 12.15869584 12.45914576  8.11604966 18.15881927\n",
      " 22.51910397 17.12145921 30.65745816 24.78995773 24.12400273  8.26049709\n",
      " 15.64114852 23.22722403 25.40477298 29.42147915  6.3348027  27.3122699\n",
      " 16.23571142 24.40731778 28.27728874 20.42599477 23.65127122 29.19607755\n",
      " 16.06025595 25.91185333 20.36135326 18.30277118 14.94836479 10.00885042\n",
      " 24.05584254 23.84322814 17.43397638 29.91967551 11.39422398 26.13849224\n",
      " 24.92807083  7.86723497 27.87111937 22.11627041  7.79684537 20.93437683\n",
      " 19.98026529 28.17874103 24.57877524 25.38260819 21.78560811 19.6605945\n",
      " 22.14920243 27.96333457 22.27844762 23.92476628  9.61461211 21.67713621\n",
      " 14.24961956 21.44653041 26.24047205 12.03453195 20.60847539 29.1404505\n",
      "  6.06677136 28.40809075 11.39762575 12.73602643 21.42463673 11.08478491\n",
      " 17.26668847 14.46590127 25.3709652  25.8422643  14.40029341 31.28716081\n",
      " 16.5459928  14.17273949 14.35678515 11.60629573 21.28566188 19.5304718\n",
      " 19.68337623 32.62206906 20.71685763 20.95997883 12.55894992 20.48682628\n",
      " 26.21953408 20.94030036 27.48245841 27.4718024  17.70182386 18.0549478\n",
      " 20.93660481 31.42488219 24.5113314  22.84221284 13.31397868 23.20560368\n",
      " 17.10289426 24.51336953 28.93060827 26.80206708 21.62768422 18.89192567\n",
      " 29.77568223 24.67645671 18.44251562  7.96664945 22.375009   19.30095446\n",
      " 13.57588528  8.8570104  26.12025118 19.26890916  7.0873405  28.41610137\n",
      " 22.05846093 23.75072938 15.28265506 15.06435981 10.0433697  13.62355675\n",
      " 28.0318494  18.37455192 17.33056597 19.96745899 24.39484481 22.63009928\n",
      " 24.61655755 22.98289319 26.09901899 20.04236161  8.05037399  4.46412863\n",
      " 17.0202717  16.23999481 23.9047867  22.07878146 19.61787855 23.86679917\n",
      " 25.37251121 26.69758784 27.7349039  16.84877341 20.92972703 10.19711463\n",
      " 26.06783544 22.05076742 28.55762234 19.2849776  12.36898322 17.4731665\n",
      " 24.89383278 19.58877018 29.01861477  8.81489577 17.16010222 24.63266649\n",
      " 23.0177614  11.00496231 21.18915398 23.31429249 24.75807574 18.79150281\n",
      " 16.40869934 19.34902566 20.28077418 28.56387798 12.45843162 24.84943285\n",
      " 13.30323069  9.45291844 35.11873319 27.10874187 19.47921492 14.74393498\n",
      " 19.01037592 26.2104469  29.49214818 19.81276711 19.0120636  16.79138559\n",
      " 24.16029985 10.42892265]\n",
      "(500,)\n",
      "Epoch 1/500\n",
      "11/11 - 0s - loss: 306.8015 - val_loss: 19.4458\n",
      "Epoch 2/500\n",
      "11/11 - 0s - loss: 18.2152 - val_loss: 12.8156\n",
      "Epoch 3/500\n",
      "11/11 - 0s - loss: 12.0868 - val_loss: 8.6123\n",
      "Epoch 4/500\n",
      "11/11 - 0s - loss: 7.6461 - val_loss: 4.7784\n",
      "Epoch 5/500\n",
      "11/11 - 0s - loss: 4.5018 - val_loss: 2.8302\n",
      "Epoch 6/500\n",
      "11/11 - 0s - loss: 2.5096 - val_loss: 1.5171\n",
      "Epoch 7/500\n",
      "11/11 - 0s - loss: 1.4672 - val_loss: 0.8348\n",
      "Epoch 8/500\n",
      "11/11 - 0s - loss: 0.8526 - val_loss: 0.4911\n",
      "Epoch 9/500\n",
      "11/11 - 0s - loss: 0.4517 - val_loss: 0.2901\n",
      "Epoch 10/500\n",
      "11/11 - 0s - loss: 0.2726 - val_loss: 0.1976\n",
      "Epoch 11/500\n",
      "11/11 - 0s - loss: 0.1662 - val_loss: 0.1095\n",
      "Epoch 12/500\n",
      "11/11 - 0s - loss: 0.1009 - val_loss: 0.0658\n",
      "Epoch 13/500\n",
      "11/11 - 0s - loss: 0.0612 - val_loss: 0.0391\n",
      "Epoch 14/500\n",
      "11/11 - 0s - loss: 0.0367 - val_loss: 0.0235\n",
      "Epoch 15/500\n",
      "11/11 - 0s - loss: 0.0212 - val_loss: 0.0158\n",
      "Epoch 16/500\n",
      "11/11 - 0s - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 17/500\n",
      "11/11 - 0s - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 18/500\n",
      "11/11 - 0s - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 19/500\n",
      "11/11 - 0s - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 20/500\n",
      "11/11 - 0s - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/500\n",
      "11/11 - 0s - loss: 0.0010 - val_loss: 8.6486e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "11/11 - 0s - loss: 6.4644e-04 - val_loss: 5.2254e-04\n",
      "Epoch 23/500\n",
      "11/11 - 0s - loss: 3.9033e-04 - val_loss: 2.7318e-04\n",
      "Epoch 24/500\n",
      "11/11 - 0s - loss: 2.4444e-04 - val_loss: 1.6625e-04\n",
      "Epoch 25/500\n",
      "11/11 - 0s - loss: 1.4985e-04 - val_loss: 1.2550e-04\n",
      "Epoch 26/500\n",
      "11/11 - 0s - loss: 9.3596e-05 - val_loss: 6.0296e-05\n",
      "Epoch 27/500\n",
      "11/11 - 0s - loss: 5.6189e-05 - val_loss: 3.6787e-05\n",
      "Epoch 28/500\n",
      "11/11 - 0s - loss: 3.5704e-05 - val_loss: 2.4600e-05\n",
      "Epoch 29/500\n",
      "11/11 - 0s - loss: 2.2249e-05 - val_loss: 1.6271e-05\n",
      "Epoch 30/500\n",
      "11/11 - 0s - loss: 1.5441e-05 - val_loss: 8.1440e-06\n",
      "Epoch 31/500\n",
      "11/11 - 0s - loss: 1.0937e-05 - val_loss: 5.5632e-06\n",
      "Epoch 32/500\n",
      "11/11 - 0s - loss: 6.8694e-06 - val_loss: 3.1008e-06\n",
      "Epoch 33/500\n",
      "11/11 - 0s - loss: 5.1760e-06 - val_loss: 1.8148e-06\n",
      "Epoch 34/500\n",
      "11/11 - 0s - loss: 3.9842e-06 - val_loss: 1.0905e-06\n",
      "Epoch 35/500\n",
      "11/11 - 0s - loss: 3.2943e-06 - val_loss: 6.9798e-07\n",
      "Epoch 36/500\n",
      "11/11 - 0s - loss: 2.9537e-06 - val_loss: 4.9447e-07\n",
      "Epoch 37/500\n",
      "11/11 - 0s - loss: 2.6867e-06 - val_loss: 3.8697e-07\n",
      "Epoch 38/500\n",
      "11/11 - 0s - loss: 2.5236e-06 - val_loss: 3.1424e-07\n",
      "Epoch 39/500\n",
      "11/11 - 0s - loss: 2.4430e-06 - val_loss: 2.8232e-07\n",
      "Epoch 40/500\n",
      "11/11 - 0s - loss: 2.3837e-06 - val_loss: 3.8013e-07\n",
      "Epoch 41/500\n",
      "11/11 - 0s - loss: 2.3498e-06 - val_loss: 2.5546e-07\n",
      "Epoch 42/500\n",
      "11/11 - 0s - loss: 2.3147e-06 - val_loss: 2.9260e-07\n",
      "Epoch 43/500\n",
      "11/11 - 0s - loss: 2.3284e-06 - val_loss: 3.0323e-07\n",
      "Epoch 44/500\n",
      "11/11 - 0s - loss: 2.2520e-06 - val_loss: 2.6243e-07\n",
      "Epoch 45/500\n",
      "11/11 - 0s - loss: 2.2383e-06 - val_loss: 2.5630e-07\n",
      "Epoch 46/500\n",
      "11/11 - 0s - loss: 2.2441e-06 - val_loss: 2.6401e-07\n",
      "Epoch 47/500\n",
      "11/11 - 0s - loss: 2.2258e-06 - val_loss: 2.7226e-07\n",
      "Epoch 48/500\n",
      "11/11 - 0s - loss: 2.2233e-06 - val_loss: 2.6736e-07\n",
      "Epoch 49/500\n",
      "11/11 - 0s - loss: 2.1973e-06 - val_loss: 2.7812e-07\n",
      "Epoch 50/500\n",
      "11/11 - 0s - loss: 2.1828e-06 - val_loss: 2.7240e-07\n",
      "Epoch 51/500\n",
      "11/11 - 0s - loss: 2.1798e-06 - val_loss: 2.7563e-07\n",
      "Epoch 52/500\n",
      "11/11 - 0s - loss: 2.1530e-06 - val_loss: 2.6509e-07\n",
      "Epoch 53/500\n",
      "11/11 - 0s - loss: 2.2090e-06 - val_loss: 2.6652e-07\n",
      "Epoch 54/500\n",
      "11/11 - 0s - loss: 2.1866e-06 - val_loss: 3.0641e-07\n",
      "Epoch 55/500\n",
      "11/11 - 0s - loss: 2.1869e-06 - val_loss: 3.0714e-07\n",
      "Epoch 56/500\n",
      "11/11 - 0s - loss: 2.1360e-06 - val_loss: 2.7065e-07\n",
      "Epoch 57/500\n",
      "11/11 - 0s - loss: 2.1162e-06 - val_loss: 2.7691e-07\n",
      "Epoch 58/500\n",
      "11/11 - 0s - loss: 2.1362e-06 - val_loss: 3.2369e-07\n",
      "Epoch 59/500\n",
      "11/11 - 0s - loss: 2.1084e-06 - val_loss: 2.8716e-07\n",
      "Epoch 60/500\n",
      "11/11 - 0s - loss: 2.1417e-06 - val_loss: 2.8911e-07\n",
      "Epoch 61/500\n",
      "11/11 - 0s - loss: 2.0775e-06 - val_loss: 2.7425e-07\n",
      "Epoch 62/500\n",
      "11/11 - 0s - loss: 2.0798e-06 - val_loss: 2.8507e-07\n",
      "Epoch 63/500\n",
      "11/11 - 0s - loss: 2.0860e-06 - val_loss: 2.6455e-07\n",
      "Epoch 64/500\n",
      "11/11 - 0s - loss: 2.0650e-06 - val_loss: 2.8468e-07\n",
      "Epoch 65/500\n",
      "11/11 - 0s - loss: 2.0577e-06 - val_loss: 4.9949e-07\n",
      "Epoch 66/500\n",
      "11/11 - 0s - loss: 2.0747e-06 - val_loss: 2.6645e-07\n",
      "Epoch 67/500\n",
      "11/11 - 0s - loss: 2.0165e-06 - val_loss: 2.6872e-07\n",
      "Epoch 68/500\n",
      "11/11 - 0s - loss: 2.0242e-06 - val_loss: 4.7523e-07\n",
      "Epoch 69/500\n",
      "11/11 - 0s - loss: 2.0189e-06 - val_loss: 2.8979e-07\n",
      "Epoch 70/500\n",
      "11/11 - 0s - loss: 1.9863e-06 - val_loss: 2.6611e-07\n",
      "Epoch 71/500\n",
      "11/11 - 0s - loss: 1.9782e-06 - val_loss: 2.6705e-07\n",
      "Epoch 72/500\n",
      "11/11 - 0s - loss: 2.0097e-06 - val_loss: 2.6775e-07\n",
      "Epoch 73/500\n",
      "11/11 - 0s - loss: 1.9844e-06 - val_loss: 2.6606e-07\n",
      "Epoch 74/500\n",
      "11/11 - 0s - loss: 1.9599e-06 - val_loss: 2.7170e-07\n",
      "Epoch 75/500\n",
      "11/11 - 0s - loss: 1.9712e-06 - val_loss: 2.7043e-07\n",
      "Epoch 76/500\n",
      "11/11 - 0s - loss: 1.9558e-06 - val_loss: 3.3140e-07\n",
      "Epoch 77/500\n",
      "11/11 - 0s - loss: 2.0138e-06 - val_loss: 2.8495e-07\n",
      "Epoch 78/500\n",
      "11/11 - 0s - loss: 1.9461e-06 - val_loss: 2.5996e-07\n",
      "Epoch 79/500\n",
      "11/11 - 0s - loss: 1.9271e-06 - val_loss: 2.7426e-07\n",
      "Epoch 80/500\n",
      "11/11 - 0s - loss: 1.9222e-06 - val_loss: 2.5827e-07\n",
      "Epoch 81/500\n",
      "11/11 - 0s - loss: 1.8889e-06 - val_loss: 3.5110e-07\n",
      "Epoch 82/500\n",
      "11/11 - 0s - loss: 1.9048e-06 - val_loss: 2.6161e-07\n",
      "Epoch 83/500\n",
      "11/11 - 0s - loss: 1.8789e-06 - val_loss: 3.5036e-07\n",
      "Epoch 84/500\n",
      "11/11 - 0s - loss: 1.8966e-06 - val_loss: 2.6563e-07\n",
      "Epoch 85/500\n",
      "11/11 - 0s - loss: 1.9029e-06 - val_loss: 2.7338e-07\n",
      "Epoch 86/500\n",
      "11/11 - 0s - loss: 1.8757e-06 - val_loss: 2.6287e-07\n",
      "Epoch 87/500\n",
      "11/11 - 0s - loss: 1.8699e-06 - val_loss: 2.6168e-07\n",
      "Epoch 88/500\n",
      "11/11 - 0s - loss: 1.8995e-06 - val_loss: 2.8350e-07\n",
      "Epoch 89/500\n",
      "11/11 - 0s - loss: 1.8328e-06 - val_loss: 2.6399e-07\n",
      "Epoch 90/500\n",
      "11/11 - 0s - loss: 1.8313e-06 - val_loss: 2.7271e-07\n",
      "Epoch 91/500\n",
      "11/11 - 0s - loss: 1.8212e-06 - val_loss: 2.7094e-07\n",
      "Epoch 92/500\n",
      "11/11 - 0s - loss: 1.8316e-06 - val_loss: 2.9820e-07\n",
      "Epoch 93/500\n",
      "11/11 - 0s - loss: 1.8149e-06 - val_loss: 2.5706e-07\n",
      "Epoch 94/500\n",
      "11/11 - 0s - loss: 1.7811e-06 - val_loss: 2.6656e-07\n",
      "Epoch 95/500\n",
      "11/11 - 0s - loss: 1.7902e-06 - val_loss: 2.8705e-07\n",
      "Epoch 96/500\n",
      "11/11 - 0s - loss: 1.8282e-06 - val_loss: 3.5693e-07\n",
      "Epoch 97/500\n",
      "11/11 - 0s - loss: 1.7742e-06 - val_loss: 2.6300e-07\n",
      "Epoch 98/500\n",
      "11/11 - 0s - loss: 1.7607e-06 - val_loss: 2.5969e-07\n",
      "Epoch 99/500\n",
      "11/11 - 0s - loss: 1.7887e-06 - val_loss: 2.6268e-07\n",
      "Epoch 100/500\n",
      "11/11 - 0s - loss: 1.7644e-06 - val_loss: 2.5432e-07\n",
      "Epoch 101/500\n",
      "11/11 - 0s - loss: 1.7696e-06 - val_loss: 2.7571e-07\n",
      "Epoch 102/500\n",
      "11/11 - 0s - loss: 1.7630e-06 - val_loss: 2.5246e-07\n",
      "Epoch 103/500\n",
      "11/11 - 0s - loss: 1.7589e-06 - val_loss: 2.4930e-07\n",
      "Epoch 104/500\n",
      "11/11 - 0s - loss: 1.7353e-06 - val_loss: 2.5506e-07\n",
      "Epoch 105/500\n",
      "11/11 - 0s - loss: 1.7338e-06 - val_loss: 2.7186e-07\n",
      "Epoch 106/500\n",
      "11/11 - 0s - loss: 1.7104e-06 - val_loss: 2.5023e-07\n",
      "Epoch 107/500\n",
      "11/11 - 0s - loss: 1.7557e-06 - val_loss: 2.6872e-07\n",
      "Epoch 108/500\n",
      "11/11 - 0s - loss: 1.7423e-06 - val_loss: 2.4689e-07\n",
      "Epoch 109/500\n",
      "11/11 - 0s - loss: 1.6982e-06 - val_loss: 2.5146e-07\n",
      "Epoch 110/500\n",
      "11/11 - 0s - loss: 1.6839e-06 - val_loss: 2.5363e-07\n",
      "Epoch 111/500\n",
      "11/11 - 0s - loss: 1.7043e-06 - val_loss: 2.5153e-07\n",
      "Epoch 112/500\n",
      "11/11 - 0s - loss: 1.6647e-06 - val_loss: 2.5362e-07\n",
      "Epoch 113/500\n",
      "11/11 - 0s - loss: 1.6815e-06 - val_loss: 2.9430e-07\n",
      "Epoch 114/500\n",
      "11/11 - 0s - loss: 1.6721e-06 - val_loss: 2.5587e-07\n",
      "Epoch 115/500\n",
      "11/11 - 0s - loss: 1.6613e-06 - val_loss: 2.5098e-07\n",
      "Epoch 116/500\n",
      "11/11 - 0s - loss: 1.6761e-06 - val_loss: 2.4978e-07\n",
      "Epoch 117/500\n",
      "11/11 - 0s - loss: 1.6309e-06 - val_loss: 2.8731e-07\n",
      "Epoch 118/500\n",
      "11/11 - 0s - loss: 1.6551e-06 - val_loss: 2.5187e-07\n",
      "Epoch 119/500\n",
      "11/11 - 0s - loss: 1.6434e-06 - val_loss: 2.5829e-07\n",
      "Epoch 120/500\n",
      "11/11 - 0s - loss: 1.6298e-06 - val_loss: 2.4872e-07\n",
      "Epoch 121/500\n",
      "11/11 - 0s - loss: 1.6261e-06 - val_loss: 2.7041e-07\n",
      "Epoch 122/500\n",
      "11/11 - 0s - loss: 1.6036e-06 - val_loss: 2.5635e-07\n",
      "Epoch 123/500\n",
      "11/11 - 0s - loss: 1.6321e-06 - val_loss: 2.7329e-07\n",
      "Epoch 124/500\n",
      "11/11 - 0s - loss: 1.6088e-06 - val_loss: 3.8548e-07\n",
      "Epoch 125/500\n",
      "11/11 - 0s - loss: 1.6024e-06 - val_loss: 2.5631e-07\n",
      "Epoch 126/500\n",
      "11/11 - 0s - loss: 1.6031e-06 - val_loss: 2.8734e-07\n",
      "Epoch 127/500\n",
      "11/11 - 0s - loss: 1.5733e-06 - val_loss: 2.4612e-07\n",
      "Epoch 128/500\n",
      "11/11 - 0s - loss: 1.5701e-06 - val_loss: 2.4425e-07\n",
      "Epoch 129/500\n",
      "11/11 - 0s - loss: 1.5801e-06 - val_loss: 2.4521e-07\n",
      "Epoch 130/500\n",
      "11/11 - 0s - loss: 1.5650e-06 - val_loss: 2.4531e-07\n",
      "Epoch 131/500\n",
      "11/11 - 0s - loss: 1.5549e-06 - val_loss: 2.4077e-07\n",
      "Epoch 132/500\n",
      "11/11 - 0s - loss: 1.6269e-06 - val_loss: 2.4588e-07\n",
      "Epoch 133/500\n",
      "11/11 - 0s - loss: 1.5439e-06 - val_loss: 2.4295e-07\n",
      "Epoch 134/500\n",
      "11/11 - 0s - loss: 1.5328e-06 - val_loss: 2.8402e-07\n",
      "Epoch 135/500\n",
      "11/11 - 0s - loss: 1.5382e-06 - val_loss: 2.5905e-07\n",
      "Epoch 136/500\n",
      "11/11 - 0s - loss: 1.5471e-06 - val_loss: 2.4807e-07\n",
      "Epoch 137/500\n",
      "11/11 - 0s - loss: 1.5202e-06 - val_loss: 2.4351e-07\n",
      "Epoch 138/500\n",
      "11/11 - 0s - loss: 1.5342e-06 - val_loss: 2.4378e-07\n",
      "Epoch 139/500\n",
      "11/11 - 0s - loss: 1.5149e-06 - val_loss: 2.4511e-07\n",
      "Epoch 140/500\n",
      "11/11 - 0s - loss: 1.5056e-06 - val_loss: 2.7436e-07\n",
      "Epoch 141/500\n",
      "11/11 - 0s - loss: 1.5288e-06 - val_loss: 2.4992e-07\n",
      "Epoch 142/500\n",
      "11/11 - 0s - loss: 1.5027e-06 - val_loss: 2.5282e-07\n",
      "Epoch 143/500\n",
      "11/11 - 0s - loss: 1.4944e-06 - val_loss: 2.3778e-07\n",
      "Epoch 144/500\n",
      "11/11 - 0s - loss: 1.4896e-06 - val_loss: 2.4340e-07\n",
      "Epoch 145/500\n",
      "11/11 - 0s - loss: 1.4970e-06 - val_loss: 3.3747e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/500\n",
      "11/11 - 0s - loss: 1.5273e-06 - val_loss: 2.4778e-07\n",
      "Epoch 147/500\n",
      "11/11 - 0s - loss: 1.4625e-06 - val_loss: 2.5309e-07\n",
      "Epoch 148/500\n",
      "11/11 - 0s - loss: 1.4567e-06 - val_loss: 2.4829e-07\n",
      "Epoch 149/500\n",
      "11/11 - 0s - loss: 1.4724e-06 - val_loss: 2.6140e-07\n",
      "Epoch 150/500\n",
      "11/11 - 0s - loss: 1.4480e-06 - val_loss: 3.6079e-07\n",
      "Epoch 151/500\n",
      "11/11 - 0s - loss: 1.4420e-06 - val_loss: 2.8165e-07\n",
      "Epoch 152/500\n",
      "11/11 - 0s - loss: 1.4870e-06 - val_loss: 2.6593e-07\n",
      "Epoch 153/500\n",
      "11/11 - 0s - loss: 1.4422e-06 - val_loss: 2.5149e-07\n",
      "Epoch 154/500\n",
      "11/11 - 0s - loss: 1.4392e-06 - val_loss: 2.9259e-07\n",
      "Epoch 155/500\n",
      "11/11 - 0s - loss: 1.4575e-06 - val_loss: 2.6443e-07\n",
      "Epoch 156/500\n",
      "11/11 - 0s - loss: 1.4132e-06 - val_loss: 2.7863e-07\n",
      "Epoch 157/500\n",
      "11/11 - 0s - loss: 1.4110e-06 - val_loss: 2.5064e-07\n",
      "Epoch 158/500\n",
      "11/11 - 0s - loss: 1.4564e-06 - val_loss: 2.4239e-07\n",
      "Epoch 159/500\n",
      "11/11 - 0s - loss: 1.4129e-06 - val_loss: 2.6579e-07\n",
      "Epoch 160/500\n",
      "11/11 - 0s - loss: 1.3960e-06 - val_loss: 2.3550e-07\n",
      "Epoch 161/500\n",
      "11/11 - 0s - loss: 1.3961e-06 - val_loss: 2.3550e-07\n",
      "Epoch 162/500\n",
      "11/11 - 0s - loss: 1.3931e-06 - val_loss: 2.9548e-07\n",
      "Epoch 163/500\n",
      "11/11 - 0s - loss: 1.3785e-06 - val_loss: 2.3411e-07\n",
      "Epoch 164/500\n",
      "11/11 - 0s - loss: 1.3901e-06 - val_loss: 2.7393e-07\n",
      "Epoch 165/500\n",
      "11/11 - 0s - loss: 1.3708e-06 - val_loss: 2.4768e-07\n",
      "Epoch 166/500\n",
      "11/11 - 0s - loss: 1.3813e-06 - val_loss: 2.3323e-07\n",
      "Epoch 167/500\n",
      "11/11 - 0s - loss: 1.3621e-06 - val_loss: 2.4456e-07\n",
      "Epoch 168/500\n",
      "11/11 - 0s - loss: 1.3782e-06 - val_loss: 2.8998e-07\n",
      "Epoch 169/500\n",
      "11/11 - 0s - loss: 1.3594e-06 - val_loss: 2.6658e-07\n",
      "Epoch 170/500\n",
      "11/11 - 0s - loss: 1.3619e-06 - val_loss: 2.3481e-07\n",
      "Epoch 171/500\n",
      "11/11 - 0s - loss: 1.4118e-06 - val_loss: 2.4854e-07\n",
      "Epoch 172/500\n",
      "11/11 - 0s - loss: 1.3552e-06 - val_loss: 2.5636e-07\n",
      "Epoch 173/500\n",
      "11/11 - 0s - loss: 1.3496e-06 - val_loss: 2.3226e-07\n",
      "Epoch 174/500\n",
      "11/11 - 0s - loss: 1.3427e-06 - val_loss: 2.5096e-07\n",
      "Epoch 175/500\n",
      "11/11 - 0s - loss: 1.3420e-06 - val_loss: 2.3707e-07\n",
      "Epoch 176/500\n",
      "11/11 - 0s - loss: 1.3362e-06 - val_loss: 3.1473e-07\n",
      "Epoch 177/500\n",
      "11/11 - 0s - loss: 1.3480e-06 - val_loss: 2.2983e-07\n",
      "Epoch 178/500\n",
      "11/11 - 0s - loss: 1.3261e-06 - val_loss: 3.0921e-07\n",
      "Epoch 179/500\n",
      "11/11 - 0s - loss: 1.3160e-06 - val_loss: 2.4169e-07\n",
      "Epoch 180/500\n",
      "11/11 - 0s - loss: 1.2993e-06 - val_loss: 2.3482e-07\n",
      "Epoch 181/500\n",
      "11/11 - 0s - loss: 1.2907e-06 - val_loss: 2.4191e-07\n",
      "Epoch 182/500\n",
      "11/11 - 0s - loss: 1.2843e-06 - val_loss: 2.5526e-07\n",
      "Epoch 183/500\n",
      "11/11 - 0s - loss: 1.3051e-06 - val_loss: 2.4087e-07\n",
      "Epoch 184/500\n",
      "11/11 - 0s - loss: 1.2885e-06 - val_loss: 2.3171e-07\n",
      "Epoch 185/500\n",
      "11/11 - 0s - loss: 1.2781e-06 - val_loss: 2.2915e-07\n",
      "Epoch 186/500\n",
      "11/11 - 0s - loss: 1.2812e-06 - val_loss: 2.3882e-07\n",
      "Epoch 187/500\n",
      "11/11 - 0s - loss: 1.2661e-06 - val_loss: 2.2917e-07\n",
      "Epoch 188/500\n",
      "11/11 - 0s - loss: 1.2630e-06 - val_loss: 3.8178e-07\n",
      "Epoch 189/500\n",
      "11/11 - 0s - loss: 1.3068e-06 - val_loss: 2.7653e-07\n",
      "Epoch 190/500\n",
      "11/11 - 0s - loss: 1.2742e-06 - val_loss: 2.3469e-07\n",
      "Epoch 191/500\n",
      "11/11 - 0s - loss: 1.2488e-06 - val_loss: 2.3710e-07\n",
      "Epoch 192/500\n",
      "11/11 - 0s - loss: 1.2578e-06 - val_loss: 2.5284e-07\n",
      "Epoch 193/500\n",
      "11/11 - 0s - loss: 1.2648e-06 - val_loss: 2.5268e-07\n",
      "Epoch 194/500\n",
      "11/11 - 0s - loss: 1.2806e-06 - val_loss: 2.2778e-07\n",
      "Epoch 195/500\n",
      "11/11 - 0s - loss: 1.2244e-06 - val_loss: 2.2808e-07\n",
      "Epoch 196/500\n",
      "11/11 - 0s - loss: 1.2495e-06 - val_loss: 2.3732e-07\n",
      "Epoch 197/500\n",
      "11/11 - 0s - loss: 1.2283e-06 - val_loss: 2.3709e-07\n",
      "Epoch 198/500\n",
      "11/11 - 0s - loss: 1.2598e-06 - val_loss: 2.4336e-07\n",
      "Epoch 199/500\n",
      "11/11 - 0s - loss: 1.2444e-06 - val_loss: 2.8696e-07\n",
      "Epoch 200/500\n",
      "11/11 - 0s - loss: 1.2232e-06 - val_loss: 2.2555e-07\n",
      "Epoch 201/500\n",
      "11/11 - 0s - loss: 1.2233e-06 - val_loss: 2.2157e-07\n",
      "Epoch 202/500\n",
      "11/11 - 0s - loss: 1.2662e-06 - val_loss: 2.9150e-07\n",
      "Epoch 203/500\n",
      "11/11 - 0s - loss: 1.2267e-06 - val_loss: 2.3271e-07\n",
      "Epoch 204/500\n",
      "11/11 - 0s - loss: 1.2223e-06 - val_loss: 2.6681e-07\n",
      "Epoch 205/500\n",
      "11/11 - 0s - loss: 1.2103e-06 - val_loss: 2.4188e-07\n",
      "Epoch 206/500\n",
      "11/11 - 0s - loss: 1.1811e-06 - val_loss: 3.0279e-07\n",
      "Epoch 207/500\n",
      "11/11 - 0s - loss: 1.2101e-06 - val_loss: 2.7691e-07\n",
      "Epoch 208/500\n",
      "11/11 - 0s - loss: 1.1935e-06 - val_loss: 2.2627e-07\n",
      "Epoch 209/500\n",
      "11/11 - 0s - loss: 1.1887e-06 - val_loss: 2.3156e-07\n",
      "Epoch 210/500\n",
      "11/11 - 0s - loss: 1.1840e-06 - val_loss: 2.2089e-07\n",
      "Epoch 211/500\n",
      "11/11 - 0s - loss: 1.2062e-06 - val_loss: 2.2531e-07\n",
      "Epoch 212/500\n",
      "11/11 - 0s - loss: 1.1710e-06 - val_loss: 3.4960e-07\n",
      "Epoch 213/500\n",
      "11/11 - 0s - loss: 1.2422e-06 - val_loss: 2.7844e-07\n",
      "Epoch 214/500\n",
      "11/11 - 0s - loss: 1.1609e-06 - val_loss: 2.2149e-07\n",
      "Epoch 215/500\n",
      "11/11 - 0s - loss: 1.1547e-06 - val_loss: 2.6412e-07\n",
      "Epoch 216/500\n",
      "11/11 - 0s - loss: 1.1594e-06 - val_loss: 2.4991e-07\n",
      "Epoch 217/500\n",
      "11/11 - 0s - loss: 1.1574e-06 - val_loss: 2.2042e-07\n",
      "Epoch 218/500\n",
      "11/11 - 0s - loss: 1.1461e-06 - val_loss: 2.2028e-07\n",
      "Epoch 219/500\n",
      "11/11 - 0s - loss: 1.1396e-06 - val_loss: 2.2161e-07\n",
      "Epoch 220/500\n",
      "11/11 - 0s - loss: 1.1614e-06 - val_loss: 2.4814e-07\n",
      "Epoch 221/500\n",
      "11/11 - 0s - loss: 1.1353e-06 - val_loss: 2.8681e-07\n",
      "Epoch 222/500\n",
      "11/11 - 0s - loss: 1.1384e-06 - val_loss: 2.1816e-07\n",
      "Epoch 223/500\n",
      "11/11 - 0s - loss: 1.1483e-06 - val_loss: 2.2886e-07\n",
      "Epoch 224/500\n",
      "11/11 - 0s - loss: 1.1258e-06 - val_loss: 2.4046e-07\n",
      "Epoch 225/500\n",
      "11/11 - 0s - loss: 1.1130e-06 - val_loss: 2.6473e-07\n",
      "Epoch 226/500\n",
      "11/11 - 0s - loss: 1.1144e-06 - val_loss: 2.1779e-07\n",
      "Epoch 227/500\n",
      "11/11 - 0s - loss: 1.1260e-06 - val_loss: 2.1866e-07\n",
      "Epoch 228/500\n",
      "11/11 - 0s - loss: 1.1160e-06 - val_loss: 2.3909e-07\n",
      "Epoch 229/500\n",
      "11/11 - 0s - loss: 1.0989e-06 - val_loss: 2.2563e-07\n",
      "Epoch 230/500\n",
      "11/11 - 0s - loss: 1.1008e-06 - val_loss: 2.2088e-07\n",
      "Epoch 231/500\n",
      "11/11 - 0s - loss: 1.1381e-06 - val_loss: 2.8103e-07\n",
      "Epoch 232/500\n",
      "11/11 - 0s - loss: 1.0922e-06 - val_loss: 2.2004e-07\n",
      "Epoch 233/500\n",
      "11/11 - 0s - loss: 1.0776e-06 - val_loss: 2.2853e-07\n",
      "Epoch 234/500\n",
      "11/11 - 0s - loss: 1.1158e-06 - val_loss: 2.2365e-07\n",
      "Epoch 235/500\n",
      "11/11 - 0s - loss: 1.0888e-06 - val_loss: 2.2095e-07\n",
      "Epoch 236/500\n",
      "11/11 - 0s - loss: 1.0759e-06 - val_loss: 2.2471e-07\n",
      "Epoch 237/500\n",
      "11/11 - 0s - loss: 1.1014e-06 - val_loss: 2.1688e-07\n",
      "Epoch 238/500\n",
      "11/11 - 0s - loss: 1.0653e-06 - val_loss: 2.1732e-07\n",
      "Epoch 239/500\n",
      "11/11 - 0s - loss: 1.0855e-06 - val_loss: 2.2669e-07\n",
      "Epoch 240/500\n",
      "11/11 - 0s - loss: 1.0769e-06 - val_loss: 2.4721e-07\n",
      "Epoch 241/500\n",
      "11/11 - 0s - loss: 1.0563e-06 - val_loss: 2.2345e-07\n",
      "Epoch 242/500\n",
      "11/11 - 0s - loss: 1.0639e-06 - val_loss: 2.1436e-07\n",
      "Epoch 243/500\n",
      "11/11 - 0s - loss: 1.0521e-06 - val_loss: 2.1365e-07\n",
      "Epoch 244/500\n",
      "11/11 - 0s - loss: 1.0614e-06 - val_loss: 3.4193e-07\n",
      "Epoch 245/500\n",
      "11/11 - 0s - loss: 1.0791e-06 - val_loss: 2.2215e-07\n",
      "Epoch 246/500\n",
      "11/11 - 0s - loss: 1.0419e-06 - val_loss: 2.5577e-07\n",
      "Epoch 247/500\n",
      "11/11 - 0s - loss: 1.0430e-06 - val_loss: 2.1378e-07\n",
      "Epoch 248/500\n",
      "11/11 - 0s - loss: 1.0255e-06 - val_loss: 2.2995e-07\n",
      "Epoch 249/500\n",
      "11/11 - 0s - loss: 1.0392e-06 - val_loss: 2.2852e-07\n",
      "Epoch 250/500\n",
      "11/11 - 0s - loss: 1.0335e-06 - val_loss: 2.4758e-07\n",
      "Epoch 251/500\n",
      "11/11 - 0s - loss: 1.0254e-06 - val_loss: 2.1392e-07\n",
      "Epoch 252/500\n",
      "11/11 - 0s - loss: 1.0369e-06 - val_loss: 2.1536e-07\n",
      "Epoch 253/500\n",
      "11/11 - 0s - loss: 1.0492e-06 - val_loss: 2.1480e-07\n",
      "Epoch 254/500\n",
      "11/11 - 0s - loss: 1.0239e-06 - val_loss: 2.1087e-07\n",
      "Epoch 255/500\n",
      "11/11 - 0s - loss: 1.0153e-06 - val_loss: 2.4486e-07\n",
      "Epoch 256/500\n",
      "11/11 - 0s - loss: 1.0039e-06 - val_loss: 2.1030e-07\n",
      "Epoch 257/500\n",
      "11/11 - 0s - loss: 1.0064e-06 - val_loss: 2.0959e-07\n",
      "Epoch 258/500\n",
      "11/11 - 0s - loss: 1.0069e-06 - val_loss: 2.0950e-07\n",
      "Epoch 259/500\n",
      "11/11 - 0s - loss: 1.0447e-06 - val_loss: 2.2494e-07\n",
      "Epoch 260/500\n",
      "11/11 - 0s - loss: 1.0085e-06 - val_loss: 2.2199e-07\n",
      "Epoch 261/500\n",
      "11/11 - 0s - loss: 1.0206e-06 - val_loss: 2.8067e-07\n",
      "Epoch 262/500\n",
      "11/11 - 0s - loss: 9.8739e-07 - val_loss: 2.0825e-07\n",
      "Epoch 263/500\n",
      "11/11 - 0s - loss: 1.0189e-06 - val_loss: 2.0790e-07\n",
      "Epoch 264/500\n",
      "11/11 - 0s - loss: 1.0076e-06 - val_loss: 2.2137e-07\n",
      "Epoch 265/500\n",
      "11/11 - 0s - loss: 1.0095e-06 - val_loss: 2.0724e-07\n",
      "Epoch 266/500\n",
      "11/11 - 0s - loss: 9.7430e-07 - val_loss: 2.0727e-07\n",
      "Epoch 267/500\n",
      "11/11 - 0s - loss: 9.8762e-07 - val_loss: 2.0605e-07\n",
      "Epoch 268/500\n",
      "11/11 - 0s - loss: 1.0035e-06 - val_loss: 2.0831e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/500\n",
      "11/11 - 0s - loss: 9.7941e-07 - val_loss: 2.0846e-07\n",
      "Epoch 270/500\n",
      "11/11 - 0s - loss: 9.7265e-07 - val_loss: 2.1989e-07\n",
      "Epoch 271/500\n",
      "11/11 - 0s - loss: 9.8134e-07 - val_loss: 2.0865e-07\n",
      "Epoch 272/500\n",
      "11/11 - 0s - loss: 9.6273e-07 - val_loss: 2.0572e-07\n",
      "Epoch 273/500\n",
      "11/11 - 0s - loss: 9.5874e-07 - val_loss: 2.1547e-07\n",
      "Epoch 274/500\n",
      "11/11 - 0s - loss: 9.5787e-07 - val_loss: 2.0599e-07\n",
      "Epoch 275/500\n",
      "11/11 - 0s - loss: 9.8261e-07 - val_loss: 2.0250e-07\n",
      "Epoch 276/500\n",
      "11/11 - 0s - loss: 9.6687e-07 - val_loss: 2.2056e-07\n",
      "Epoch 277/500\n",
      "11/11 - 0s - loss: 9.5571e-07 - val_loss: 2.2168e-07\n",
      "Epoch 278/500\n",
      "11/11 - 0s - loss: 9.5723e-07 - val_loss: 2.2250e-07\n",
      "Epoch 279/500\n",
      "11/11 - 0s - loss: 9.5390e-07 - val_loss: 2.0457e-07\n",
      "Epoch 280/500\n",
      "11/11 - 0s - loss: 9.5611e-07 - val_loss: 2.4423e-07\n",
      "Epoch 281/500\n",
      "11/11 - 0s - loss: 9.5262e-07 - val_loss: 2.2041e-07\n",
      "Epoch 282/500\n",
      "11/11 - 0s - loss: 9.5816e-07 - val_loss: 2.0735e-07\n",
      "Epoch 283/500\n",
      "11/11 - 0s - loss: 9.3927e-07 - val_loss: 3.1046e-07\n",
      "Epoch 284/500\n",
      "11/11 - 0s - loss: 9.9075e-07 - val_loss: 2.3195e-07\n",
      "Epoch 285/500\n",
      "11/11 - 0s - loss: 9.2786e-07 - val_loss: 2.0220e-07\n",
      "Epoch 286/500\n",
      "11/11 - 0s - loss: 9.2442e-07 - val_loss: 2.1296e-07\n",
      "Epoch 287/500\n",
      "11/11 - 0s - loss: 9.3310e-07 - val_loss: 2.3351e-07\n",
      "Epoch 288/500\n",
      "11/11 - 0s - loss: 9.3122e-07 - val_loss: 2.0574e-07\n",
      "Epoch 289/500\n",
      "11/11 - 0s - loss: 9.2193e-07 - val_loss: 2.0012e-07\n",
      "Epoch 290/500\n",
      "11/11 - 0s - loss: 9.1671e-07 - val_loss: 1.9989e-07\n",
      "Epoch 291/500\n",
      "11/11 - 0s - loss: 9.4343e-07 - val_loss: 2.1464e-07\n",
      "Epoch 292/500\n",
      "11/11 - 0s - loss: 9.1415e-07 - val_loss: 2.3018e-07\n",
      "Epoch 293/500\n",
      "11/11 - 0s - loss: 9.4963e-07 - val_loss: 2.0201e-07\n",
      "Epoch 294/500\n",
      "11/11 - 0s - loss: 9.1322e-07 - val_loss: 2.0331e-07\n",
      "Epoch 295/500\n",
      "11/11 - 0s - loss: 9.2069e-07 - val_loss: 2.1487e-07\n",
      "Epoch 296/500\n",
      "11/11 - 0s - loss: 9.0051e-07 - val_loss: 2.0269e-07\n",
      "Epoch 297/500\n",
      "11/11 - 0s - loss: 8.9784e-07 - val_loss: 2.0309e-07\n",
      "Epoch 298/500\n",
      "11/11 - 0s - loss: 8.8112e-07 - val_loss: 2.0310e-07\n",
      "Epoch 299/500\n",
      "11/11 - 0s - loss: 8.8989e-07 - val_loss: 2.9825e-07\n",
      "Epoch 300/500\n",
      "11/11 - 0s - loss: 8.8493e-07 - val_loss: 3.0461e-07\n",
      "Epoch 301/500\n",
      "11/11 - 0s - loss: 8.9746e-07 - val_loss: 2.0053e-07\n",
      "Epoch 302/500\n",
      "11/11 - 0s - loss: 8.8313e-07 - val_loss: 2.0052e-07\n",
      "Epoch 303/500\n",
      "11/11 - 0s - loss: 8.8761e-07 - val_loss: 2.0195e-07\n",
      "Epoch 304/500\n",
      "11/11 - 0s - loss: 8.8909e-07 - val_loss: 2.0539e-07\n",
      "Epoch 305/500\n",
      "11/11 - 0s - loss: 8.7364e-07 - val_loss: 2.0754e-07\n",
      "Epoch 306/500\n",
      "11/11 - 0s - loss: 8.6810e-07 - val_loss: 2.1469e-07\n",
      "Epoch 307/500\n",
      "11/11 - 0s - loss: 9.0738e-07 - val_loss: 2.1033e-07\n",
      "Epoch 308/500\n",
      "11/11 - 0s - loss: 8.9025e-07 - val_loss: 3.1638e-07\n",
      "Epoch 309/500\n",
      "11/11 - 0s - loss: 8.7454e-07 - val_loss: 2.0025e-07\n",
      "Epoch 310/500\n",
      "11/11 - 0s - loss: 8.6234e-07 - val_loss: 1.9849e-07\n",
      "Epoch 311/500\n",
      "11/11 - 0s - loss: 8.6148e-07 - val_loss: 1.9764e-07\n",
      "Epoch 312/500\n",
      "11/11 - 0s - loss: 8.8029e-07 - val_loss: 2.1483e-07\n",
      "Epoch 313/500\n",
      "11/11 - 0s - loss: 8.5039e-07 - val_loss: 2.1943e-07\n",
      "Epoch 314/500\n",
      "11/11 - 0s - loss: 8.6055e-07 - val_loss: 2.1237e-07\n",
      "Epoch 315/500\n",
      "11/11 - 0s - loss: 8.6653e-07 - val_loss: 2.0445e-07\n",
      "Epoch 316/500\n",
      "11/11 - 0s - loss: 8.4776e-07 - val_loss: 2.0128e-07\n",
      "Epoch 317/500\n",
      "11/11 - 0s - loss: 8.3840e-07 - val_loss: 2.1099e-07\n",
      "Epoch 318/500\n",
      "11/11 - 0s - loss: 8.3667e-07 - val_loss: 2.7244e-07\n",
      "Epoch 319/500\n",
      "11/11 - 0s - loss: 8.5988e-07 - val_loss: 2.0456e-07\n",
      "Epoch 320/500\n",
      "11/11 - 0s - loss: 8.3626e-07 - val_loss: 1.9576e-07\n",
      "Epoch 321/500\n",
      "11/11 - 0s - loss: 8.4927e-07 - val_loss: 1.9547e-07\n",
      "Epoch 322/500\n",
      "11/11 - 0s - loss: 8.2867e-07 - val_loss: 1.9751e-07\n",
      "Epoch 323/500\n",
      "11/11 - 0s - loss: 8.4465e-07 - val_loss: 2.0806e-07\n",
      "Epoch 324/500\n",
      "11/11 - 0s - loss: 8.2639e-07 - val_loss: 1.9499e-07\n",
      "Epoch 325/500\n",
      "11/11 - 0s - loss: 8.2806e-07 - val_loss: 1.9445e-07\n",
      "Epoch 326/500\n",
      "11/11 - 0s - loss: 8.4466e-07 - val_loss: 2.0096e-07\n",
      "Epoch 327/500\n",
      "11/11 - 0s - loss: 8.2449e-07 - val_loss: 2.4773e-07\n",
      "Epoch 328/500\n",
      "11/11 - 0s - loss: 8.2519e-07 - val_loss: 1.9879e-07\n",
      "Epoch 329/500\n",
      "11/11 - 0s - loss: 8.5581e-07 - val_loss: 1.9383e-07\n",
      "Epoch 330/500\n",
      "11/11 - 0s - loss: 8.2199e-07 - val_loss: 1.9782e-07\n",
      "Epoch 331/500\n",
      "11/11 - 0s - loss: 8.3938e-07 - val_loss: 1.9344e-07\n",
      "Epoch 332/500\n",
      "11/11 - 0s - loss: 8.0993e-07 - val_loss: 2.1473e-07\n",
      "Epoch 333/500\n",
      "11/11 - 0s - loss: 8.1027e-07 - val_loss: 2.9149e-07\n",
      "Epoch 334/500\n",
      "11/11 - 0s - loss: 8.2331e-07 - val_loss: 2.1728e-07\n",
      "Epoch 335/500\n",
      "11/11 - 0s - loss: 8.0671e-07 - val_loss: 2.1453e-07\n",
      "Epoch 336/500\n",
      "11/11 - 0s - loss: 8.1744e-07 - val_loss: 2.1578e-07\n",
      "Epoch 337/500\n",
      "11/11 - 0s - loss: 7.9902e-07 - val_loss: 2.0762e-07\n",
      "Epoch 338/500\n",
      "11/11 - 0s - loss: 7.9431e-07 - val_loss: 2.2607e-07\n",
      "Epoch 339/500\n",
      "11/11 - 0s - loss: 8.0361e-07 - val_loss: 2.4182e-07\n",
      "Epoch 340/500\n",
      "11/11 - 0s - loss: 7.9986e-07 - val_loss: 2.0282e-07\n",
      "Epoch 341/500\n",
      "11/11 - 0s - loss: 8.2630e-07 - val_loss: 2.0619e-07\n",
      "Epoch 342/500\n",
      "11/11 - 0s - loss: 7.9740e-07 - val_loss: 2.0143e-07\n",
      "Epoch 343/500\n",
      "11/11 - 0s - loss: 7.8519e-07 - val_loss: 2.1411e-07\n",
      "Epoch 344/500\n",
      "11/11 - 0s - loss: 7.8183e-07 - val_loss: 2.0923e-07\n",
      "Epoch 345/500\n",
      "11/11 - 0s - loss: 7.8513e-07 - val_loss: 1.9389e-07\n",
      "Epoch 346/500\n",
      "11/11 - 0s - loss: 7.8285e-07 - val_loss: 1.9476e-07\n",
      "Epoch 347/500\n",
      "11/11 - 0s - loss: 7.7527e-07 - val_loss: 2.0949e-07\n",
      "Epoch 348/500\n",
      "11/11 - 0s - loss: 7.7863e-07 - val_loss: 1.9358e-07\n",
      "Epoch 349/500\n",
      "11/11 - 0s - loss: 7.8419e-07 - val_loss: 2.1218e-07\n",
      "Epoch 350/500\n",
      "11/11 - 0s - loss: 7.8995e-07 - val_loss: 1.9211e-07\n",
      "Epoch 351/500\n",
      "11/11 - 0s - loss: 7.9049e-07 - val_loss: 1.9558e-07\n",
      "Epoch 352/500\n",
      "11/11 - 0s - loss: 7.7303e-07 - val_loss: 2.0808e-07\n",
      "Epoch 353/500\n",
      "11/11 - 0s - loss: 7.7324e-07 - val_loss: 1.9090e-07\n",
      "Epoch 354/500\n",
      "11/11 - 0s - loss: 7.9428e-07 - val_loss: 2.6333e-07\n",
      "Epoch 355/500\n",
      "11/11 - 0s - loss: 7.9105e-07 - val_loss: 1.9296e-07\n",
      "Epoch 356/500\n",
      "11/11 - 0s - loss: 7.5816e-07 - val_loss: 2.0250e-07\n",
      "Epoch 357/500\n",
      "11/11 - 0s - loss: 7.7446e-07 - val_loss: 2.8798e-07\n",
      "Epoch 358/500\n",
      "11/11 - 0s - loss: 7.6507e-07 - val_loss: 1.9190e-07\n",
      "Epoch 359/500\n",
      "11/11 - 0s - loss: 7.5503e-07 - val_loss: 1.9186e-07\n",
      "Epoch 360/500\n",
      "11/11 - 0s - loss: 7.6072e-07 - val_loss: 2.5174e-07\n",
      "Epoch 361/500\n",
      "11/11 - 0s - loss: 7.5358e-07 - val_loss: 1.9362e-07\n",
      "Epoch 362/500\n",
      "11/11 - 0s - loss: 7.5041e-07 - val_loss: 1.9084e-07\n",
      "Epoch 363/500\n",
      "11/11 - 0s - loss: 7.7340e-07 - val_loss: 1.9885e-07\n",
      "Epoch 364/500\n",
      "11/11 - 0s - loss: 7.5526e-07 - val_loss: 1.8935e-07\n",
      "Epoch 365/500\n",
      "11/11 - 0s - loss: 7.4120e-07 - val_loss: 1.9133e-07\n",
      "Epoch 366/500\n",
      "11/11 - 0s - loss: 7.5824e-07 - val_loss: 3.7624e-07\n",
      "Epoch 367/500\n",
      "11/11 - 0s - loss: 7.5839e-07 - val_loss: 2.1989e-07\n",
      "Epoch 368/500\n",
      "11/11 - 0s - loss: 7.3753e-07 - val_loss: 2.0702e-07\n",
      "Epoch 369/500\n",
      "11/11 - 0s - loss: 7.3200e-07 - val_loss: 1.9176e-07\n",
      "Epoch 370/500\n",
      "11/11 - 0s - loss: 7.4823e-07 - val_loss: 1.8865e-07\n",
      "Epoch 371/500\n",
      "11/11 - 0s - loss: 7.7186e-07 - val_loss: 2.2930e-07\n",
      "Epoch 372/500\n",
      "11/11 - 0s - loss: 7.5003e-07 - val_loss: 1.9905e-07\n",
      "Epoch 373/500\n",
      "11/11 - 0s - loss: 7.4079e-07 - val_loss: 1.8867e-07\n",
      "Epoch 374/500\n",
      "11/11 - 0s - loss: 7.5854e-07 - val_loss: 1.9199e-07\n",
      "Epoch 375/500\n",
      "11/11 - 0s - loss: 7.2823e-07 - val_loss: 1.9152e-07\n",
      "Epoch 376/500\n",
      "11/11 - 0s - loss: 7.3109e-07 - val_loss: 1.9085e-07\n",
      "Epoch 377/500\n",
      "11/11 - 0s - loss: 7.1637e-07 - val_loss: 2.2434e-07\n",
      "Epoch 378/500\n",
      "11/11 - 0s - loss: 7.2013e-07 - val_loss: 2.0173e-07\n",
      "Epoch 379/500\n",
      "11/11 - 0s - loss: 7.2262e-07 - val_loss: 1.8936e-07\n",
      "Epoch 380/500\n",
      "11/11 - 0s - loss: 7.3820e-07 - val_loss: 1.8710e-07\n",
      "Epoch 381/500\n",
      "11/11 - 0s - loss: 7.2378e-07 - val_loss: 2.3030e-07\n",
      "Epoch 382/500\n",
      "11/11 - 0s - loss: 7.3406e-07 - val_loss: 1.8875e-07\n",
      "Epoch 383/500\n",
      "11/11 - 0s - loss: 7.0857e-07 - val_loss: 1.8622e-07\n",
      "Epoch 384/500\n",
      "11/11 - 0s - loss: 7.1878e-07 - val_loss: 1.8767e-07\n",
      "Epoch 385/500\n",
      "11/11 - 0s - loss: 7.3292e-07 - val_loss: 1.8526e-07\n",
      "Epoch 386/500\n",
      "11/11 - 0s - loss: 7.3656e-07 - val_loss: 1.8482e-07\n",
      "Epoch 387/500\n",
      "11/11 - 0s - loss: 6.9933e-07 - val_loss: 1.8462e-07\n",
      "Epoch 388/500\n",
      "11/11 - 0s - loss: 7.0726e-07 - val_loss: 1.9086e-07\n",
      "Epoch 389/500\n",
      "11/11 - 0s - loss: 7.0089e-07 - val_loss: 1.9129e-07\n",
      "Epoch 390/500\n",
      "11/11 - 0s - loss: 7.0181e-07 - val_loss: 2.2343e-07\n",
      "Epoch 391/500\n",
      "11/11 - 0s - loss: 7.1633e-07 - val_loss: 1.9061e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500\n",
      "11/11 - 0s - loss: 7.1129e-07 - val_loss: 1.9277e-07\n",
      "Epoch 393/500\n",
      "11/11 - 0s - loss: 7.1453e-07 - val_loss: 1.8588e-07\n",
      "Epoch 394/500\n",
      "11/11 - 0s - loss: 7.0225e-07 - val_loss: 1.8623e-07\n",
      "Epoch 395/500\n",
      "11/11 - 0s - loss: 6.9193e-07 - val_loss: 2.3719e-07\n",
      "Epoch 396/500\n",
      "11/11 - 0s - loss: 6.9436e-07 - val_loss: 2.0429e-07\n",
      "Epoch 397/500\n",
      "11/11 - 0s - loss: 6.8809e-07 - val_loss: 2.3007e-07\n",
      "Epoch 398/500\n",
      "11/11 - 0s - loss: 7.0760e-07 - val_loss: 1.8681e-07\n",
      "Epoch 399/500\n",
      "11/11 - 0s - loss: 7.1608e-07 - val_loss: 1.8933e-07\n",
      "Epoch 400/500\n",
      "11/11 - 0s - loss: 6.8283e-07 - val_loss: 1.9484e-07\n",
      "Epoch 401/500\n",
      "11/11 - 0s - loss: 6.9214e-07 - val_loss: 1.8650e-07\n",
      "Epoch 402/500\n",
      "11/11 - 0s - loss: 6.7468e-07 - val_loss: 1.9682e-07\n",
      "Epoch 403/500\n",
      "11/11 - 0s - loss: 6.7613e-07 - val_loss: 1.8352e-07\n",
      "Epoch 404/500\n",
      "11/11 - 0s - loss: 6.8850e-07 - val_loss: 3.0557e-07\n",
      "Epoch 405/500\n",
      "11/11 - 0s - loss: 6.9501e-07 - val_loss: 2.0886e-07\n",
      "Epoch 406/500\n",
      "11/11 - 0s - loss: 6.8942e-07 - val_loss: 1.8650e-07\n",
      "Epoch 407/500\n",
      "11/11 - 0s - loss: 6.8021e-07 - val_loss: 2.1382e-07\n",
      "Epoch 408/500\n",
      "11/11 - 0s - loss: 6.8128e-07 - val_loss: 1.9599e-07\n",
      "Epoch 409/500\n",
      "11/11 - 0s - loss: 6.7393e-07 - val_loss: 2.0149e-07\n",
      "Epoch 410/500\n",
      "11/11 - 0s - loss: 6.6532e-07 - val_loss: 2.0484e-07\n",
      "Epoch 411/500\n",
      "11/11 - 0s - loss: 6.9277e-07 - val_loss: 1.8446e-07\n",
      "Epoch 412/500\n",
      "11/11 - 0s - loss: 6.6325e-07 - val_loss: 1.9255e-07\n",
      "Epoch 413/500\n",
      "11/11 - 0s - loss: 6.8793e-07 - val_loss: 2.1600e-07\n",
      "Epoch 414/500\n",
      "11/11 - 0s - loss: 6.6947e-07 - val_loss: 2.1498e-07\n",
      "Epoch 415/500\n",
      "11/11 - 0s - loss: 6.6734e-07 - val_loss: 1.8311e-07\n",
      "Epoch 416/500\n",
      "11/11 - 0s - loss: 6.5915e-07 - val_loss: 1.7876e-07\n",
      "Epoch 417/500\n",
      "11/11 - 0s - loss: 6.5724e-07 - val_loss: 1.8656e-07\n",
      "Epoch 418/500\n",
      "11/11 - 0s - loss: 6.5954e-07 - val_loss: 2.1195e-07\n",
      "Epoch 419/500\n",
      "11/11 - 0s - loss: 6.6999e-07 - val_loss: 1.8454e-07\n",
      "Epoch 420/500\n",
      "11/11 - 0s - loss: 6.7314e-07 - val_loss: 1.8653e-07\n",
      "Epoch 421/500\n",
      "11/11 - 0s - loss: 6.6151e-07 - val_loss: 1.8315e-07\n",
      "Epoch 422/500\n",
      "11/11 - 0s - loss: 6.6738e-07 - val_loss: 1.8722e-07\n",
      "Epoch 423/500\n",
      "11/11 - 0s - loss: 6.4475e-07 - val_loss: 1.9118e-07\n",
      "Epoch 424/500\n",
      "11/11 - 0s - loss: 6.5859e-07 - val_loss: 1.8147e-07\n",
      "Epoch 425/500\n",
      "11/11 - 0s - loss: 6.4241e-07 - val_loss: 1.7926e-07\n",
      "Epoch 426/500\n",
      "11/11 - 0s - loss: 6.4701e-07 - val_loss: 2.0115e-07\n",
      "Epoch 427/500\n",
      "11/11 - 0s - loss: 6.4828e-07 - val_loss: 1.8547e-07\n",
      "Epoch 428/500\n",
      "11/11 - 0s - loss: 6.6359e-07 - val_loss: 1.8954e-07\n",
      "Epoch 429/500\n",
      "11/11 - 0s - loss: 6.5930e-07 - val_loss: 1.7661e-07\n",
      "Epoch 430/500\n",
      "11/11 - 0s - loss: 6.3032e-07 - val_loss: 2.1140e-07\n",
      "Epoch 431/500\n",
      "11/11 - 0s - loss: 6.4251e-07 - val_loss: 2.3017e-07\n",
      "Epoch 432/500\n",
      "11/11 - 0s - loss: 6.4497e-07 - val_loss: 2.1896e-07\n",
      "Epoch 433/500\n",
      "11/11 - 0s - loss: 6.3306e-07 - val_loss: 1.7856e-07\n",
      "Epoch 434/500\n",
      "11/11 - 0s - loss: 6.2807e-07 - val_loss: 1.7946e-07\n",
      "Epoch 435/500\n",
      "11/11 - 0s - loss: 6.3826e-07 - val_loss: 1.7547e-07\n",
      "Epoch 436/500\n",
      "11/11 - 0s - loss: 6.3930e-07 - val_loss: 1.8473e-07\n",
      "Epoch 437/500\n",
      "11/11 - 0s - loss: 6.2629e-07 - val_loss: 1.8235e-07\n",
      "Epoch 438/500\n",
      "11/11 - 0s - loss: 6.4032e-07 - val_loss: 1.8853e-07\n",
      "Epoch 439/500\n",
      "11/11 - 0s - loss: 6.5314e-07 - val_loss: 3.3902e-07\n",
      "Epoch 440/500\n",
      "11/11 - 0s - loss: 6.4757e-07 - val_loss: 2.3999e-07\n",
      "Epoch 441/500\n",
      "11/11 - 0s - loss: 6.3168e-07 - val_loss: 1.8749e-07\n",
      "Epoch 442/500\n",
      "11/11 - 0s - loss: 6.3531e-07 - val_loss: 1.8597e-07\n",
      "Epoch 443/500\n",
      "11/11 - 0s - loss: 6.3070e-07 - val_loss: 1.8730e-07\n",
      "Epoch 444/500\n",
      "11/11 - 0s - loss: 6.1651e-07 - val_loss: 1.9825e-07\n",
      "Epoch 445/500\n",
      "11/11 - 0s - loss: 6.2241e-07 - val_loss: 1.7781e-07\n",
      "Epoch 446/500\n",
      "11/11 - 0s - loss: 6.2567e-07 - val_loss: 1.8918e-07\n",
      "Epoch 447/500\n",
      "11/11 - 0s - loss: 6.1978e-07 - val_loss: 1.7514e-07\n",
      "Epoch 448/500\n",
      "11/11 - 0s - loss: 6.1401e-07 - val_loss: 1.8240e-07\n",
      "Epoch 449/500\n",
      "11/11 - 0s - loss: 6.1205e-07 - val_loss: 1.7537e-07\n",
      "Epoch 450/500\n",
      "11/11 - 0s - loss: 6.1498e-07 - val_loss: 1.8142e-07\n",
      "Epoch 451/500\n",
      "11/11 - 0s - loss: 6.3039e-07 - val_loss: 1.7503e-07\n",
      "Epoch 452/500\n",
      "11/11 - 0s - loss: 6.1548e-07 - val_loss: 1.8726e-07\n",
      "Epoch 453/500\n",
      "11/11 - 0s - loss: 6.1310e-07 - val_loss: 1.7839e-07\n",
      "Epoch 454/500\n",
      "11/11 - 0s - loss: 6.1126e-07 - val_loss: 2.0180e-07\n",
      "Epoch 455/500\n",
      "11/11 - 0s - loss: 6.0588e-07 - val_loss: 2.0804e-07\n",
      "Epoch 456/500\n",
      "11/11 - 0s - loss: 6.2454e-07 - val_loss: 1.7664e-07\n",
      "Epoch 457/500\n",
      "11/11 - 0s - loss: 6.1306e-07 - val_loss: 1.7489e-07\n",
      "Epoch 458/500\n",
      "11/11 - 0s - loss: 6.0148e-07 - val_loss: 1.7371e-07\n",
      "Epoch 459/500\n",
      "11/11 - 0s - loss: 6.0434e-07 - val_loss: 1.7312e-07\n",
      "Epoch 460/500\n",
      "11/11 - 0s - loss: 6.1167e-07 - val_loss: 1.7198e-07\n",
      "Epoch 461/500\n",
      "11/11 - 0s - loss: 6.0869e-07 - val_loss: 1.7294e-07\n",
      "Epoch 462/500\n",
      "11/11 - 0s - loss: 6.0639e-07 - val_loss: 1.7179e-07\n",
      "Epoch 463/500\n",
      "11/11 - 0s - loss: 5.9611e-07 - val_loss: 1.7162e-07\n",
      "Epoch 464/500\n",
      "11/11 - 0s - loss: 6.0165e-07 - val_loss: 1.7451e-07\n",
      "Epoch 465/500\n",
      "11/11 - 0s - loss: 6.0284e-07 - val_loss: 1.9207e-07\n",
      "Epoch 466/500\n",
      "11/11 - 0s - loss: 5.9285e-07 - val_loss: 1.8375e-07\n",
      "Epoch 467/500\n",
      "11/11 - 0s - loss: 5.9042e-07 - val_loss: 1.6990e-07\n",
      "Epoch 468/500\n",
      "11/11 - 0s - loss: 6.0186e-07 - val_loss: 2.0098e-07\n",
      "Epoch 469/500\n",
      "11/11 - 0s - loss: 6.0108e-07 - val_loss: 1.7074e-07\n",
      "Epoch 470/500\n",
      "11/11 - 0s - loss: 6.0538e-07 - val_loss: 1.6930e-07\n",
      "Epoch 471/500\n",
      "11/11 - 0s - loss: 5.8323e-07 - val_loss: 1.7453e-07\n",
      "Epoch 472/500\n",
      "11/11 - 0s - loss: 6.0189e-07 - val_loss: 1.7214e-07\n",
      "Epoch 473/500\n",
      "11/11 - 0s - loss: 5.9323e-07 - val_loss: 2.1876e-07\n",
      "Epoch 474/500\n",
      "11/11 - 0s - loss: 5.9549e-07 - val_loss: 1.8413e-07\n",
      "Epoch 475/500\n",
      "11/11 - 0s - loss: 5.7668e-07 - val_loss: 1.7300e-07\n",
      "Epoch 476/500\n",
      "11/11 - 0s - loss: 6.0129e-07 - val_loss: 1.8798e-07\n",
      "Epoch 477/500\n",
      "11/11 - 0s - loss: 5.9789e-07 - val_loss: 2.9056e-07\n",
      "Epoch 478/500\n",
      "11/11 - 0s - loss: 5.8602e-07 - val_loss: 1.8102e-07\n",
      "Epoch 479/500\n",
      "11/11 - 0s - loss: 5.7425e-07 - val_loss: 1.7305e-07\n",
      "Epoch 480/500\n",
      "11/11 - 0s - loss: 5.7365e-07 - val_loss: 1.9261e-07\n",
      "Epoch 481/500\n",
      "11/11 - 0s - loss: 5.7873e-07 - val_loss: 1.8779e-07\n",
      "Epoch 482/500\n",
      "11/11 - 0s - loss: 5.8138e-07 - val_loss: 1.6872e-07\n",
      "Epoch 483/500\n",
      "11/11 - 0s - loss: 5.7475e-07 - val_loss: 1.6944e-07\n",
      "Epoch 484/500\n",
      "11/11 - 0s - loss: 5.6543e-07 - val_loss: 1.8621e-07\n",
      "Epoch 485/500\n",
      "11/11 - 0s - loss: 5.7572e-07 - val_loss: 1.7187e-07\n",
      "Epoch 486/500\n",
      "11/11 - 0s - loss: 5.6846e-07 - val_loss: 1.7053e-07\n",
      "Epoch 487/500\n",
      "11/11 - 0s - loss: 5.6604e-07 - val_loss: 1.7025e-07\n",
      "Epoch 488/500\n",
      "11/11 - 0s - loss: 5.8967e-07 - val_loss: 1.8967e-07\n",
      "Epoch 489/500\n",
      "11/11 - 0s - loss: 5.8132e-07 - val_loss: 1.6630e-07\n",
      "Epoch 490/500\n",
      "11/11 - 0s - loss: 5.8409e-07 - val_loss: 1.6590e-07\n",
      "Epoch 491/500\n",
      "11/11 - 0s - loss: 5.6389e-07 - val_loss: 1.8365e-07\n",
      "Epoch 492/500\n",
      "11/11 - 0s - loss: 5.6258e-07 - val_loss: 1.6965e-07\n",
      "Epoch 493/500\n",
      "11/11 - 0s - loss: 5.7941e-07 - val_loss: 1.6978e-07\n",
      "Epoch 494/500\n",
      "11/11 - 0s - loss: 5.6315e-07 - val_loss: 1.8254e-07\n",
      "Epoch 495/500\n",
      "11/11 - 0s - loss: 5.5926e-07 - val_loss: 1.6802e-07\n",
      "Epoch 496/500\n",
      "11/11 - 0s - loss: 5.7988e-07 - val_loss: 1.6522e-07\n",
      "Epoch 497/500\n",
      "11/11 - 0s - loss: 5.5733e-07 - val_loss: 1.6750e-07\n",
      "Epoch 498/500\n",
      "11/11 - 0s - loss: 5.5861e-07 - val_loss: 1.6758e-07\n",
      "Epoch 499/500\n",
      "11/11 - 0s - loss: 5.5378e-07 - val_loss: 1.7572e-07\n",
      "Epoch 500/500\n",
      "11/11 - 0s - loss: 5.6379e-07 - val_loss: 1.7878e-07\n",
      "train loss =  5.637949698211742e-07\n",
      "test loss =  1.787764745131426e-07\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020155945828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Actual Y value :  17.3\n",
      "Predicted Y value :  17.299809\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# KERAS NN으로 model을 구성하는 함수\n",
    "def Gen_Sequential_Model():\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(4, name = \"input_layer\"),\n",
    "        Dense(16, activation = \"relu\", name = \"hidden_layer1\", kernel_initializer = initializers.RandomNormal(mean=0, stddev=0.05, seed=42)),\n",
    "        Dense(1, activation = 'relu', name = \"output_layer\", kernel_initializer = initializers.RandomNormal(mean=0, stddev=0.05, seed=42))\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# y = a + bx1 + cx2^2 + dx3^3 + ex4^4\n",
    "# 데이터 샘플을 생성하는 함수\n",
    "def Gen_Linear_Regression_Dataset(numOfSamples = 500, a=1, b=3, c=5, d=10, e=20):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(numOfSamples, 4)\n",
    "    \n",
    "    print(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "    coef = np.array([b, c, d, e])\n",
    "    bias = a\n",
    "    \n",
    "    print(coef)\n",
    "    print(coef.shape)\n",
    "    \n",
    "    y = np.matmul(X, coef.transpose()) + bias\n",
    "    \n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "# 학습결과를 출력/분석하는 함수\n",
    "def loss_Result(history):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize = (15,10))\n",
    "    \n",
    "    plt.plot(history.history['loss'][1:])\n",
    "    plt.plot(history.history['val_loss'][1:])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc= 'upper right')\n",
    "    \n",
    "    print(\"train loss = \", history.history['loss'][-1])\n",
    "    print(\"test loss = \", history.history['val_loss'][-1])\n",
    "    \n",
    "#학습된 model에 임의의 입력변수를 입력으로 받아서, y값을 예측하는 함수\n",
    "def predict_New_Sample(model, x, a=1, b=3, c=5, d=10, e=20):   \n",
    "    \n",
    "    x = x.reshape(1,4)\n",
    "    y_pred = model.predict(x)[0][0]\n",
    "    y_actual = a + b*x[0][0] + c*x[0][1] + d*x[0][2] + e*x[0][3]\n",
    "    \n",
    "    print(\"Actual Y value : \", y_actual)\n",
    "    print(\"Predicted Y value : \", y_pred)\n",
    "    \n",
    "    \n",
    "model = Gen_Sequential_Model()\n",
    "X, y = Gen_Linear_Regression_Dataset(numOfSamples = \n",
    "500)\n",
    "# KERAS NN을 학습시키는 함수\n",
    "history = model.fit(X, y, epochs = 500, verbose = 2, validation_split=0.3)\n",
    "loss_Result(history)\n",
    "# new 데이터 확인\n",
    "predict_New_Sample(model, np.array([0.6, 0.3, 0.5, 0.4]))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
